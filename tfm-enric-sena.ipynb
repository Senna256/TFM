{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11243975,"sourceType":"datasetVersion","datasetId":7025358}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#TFM UNIR BIG DATA","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:19:44.393867Z","iopub.execute_input":"2025-05-30T17:19:44.394390Z","iopub.status.idle":"2025-05-30T17:19:44.400979Z","shell.execute_reply.started":"2025-05-30T17:19:44.394345Z","shell.execute_reply":"2025-05-30T17:19:44.399507Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\nfrom collections import Counter\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier \nfrom sklearn.svm import SVC\nimport warnings\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout,LSTM\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout,\n    Multiply, Permute, Lambda, Activation, Concatenate\n)\nfrom tensorflow.keras import backend as K\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:24:37.585841Z","iopub.execute_input":"2025-05-30T18:24:37.586186Z","iopub.status.idle":"2025-05-30T18:24:37.593807Z","shell.execute_reply.started":"2025-05-30T18:24:37.586160Z","shell.execute_reply":"2025-05-30T18:24:37.592341Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/dataset/preus_tancament_r.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:36:55.875902Z","iopub.execute_input":"2025-05-30T17:36:55.876264Z","iopub.status.idle":"2025-05-30T17:36:56.001161Z","shell.execute_reply.started":"2025-05-30T17:36:55.876238Z","shell.execute_reply":"2025-05-30T17:36:56.000147Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"assets = ['AAPL', 'AMS', 'AMZN', 'BBVA', 'CABK', 'CLNX', 'FER', 'GOOGL', 'GSPC', 'IBE', \n 'IBEX', 'ITX', 'IXIC', 'JPM', 'LLY', 'META', 'MSFT', 'NVDA', 'SAN', 'TEF', 'TSLA']\n\n# Inicialitzar DataFrame de treball\ndf_features = df\ndf_features['Date'] = pd.to_datetime(df['Date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:36:58.040688Z","iopub.execute_input":"2025-05-30T17:36:58.041171Z","iopub.status.idle":"2025-05-30T17:36:58.055161Z","shell.execute_reply.started":"2025-05-30T17:36:58.041132Z","shell.execute_reply":"2025-05-30T17:36:58.053588Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\n# Per a cada actiu, generem les següents variables:\n# - Retorn diari\n# - Target (1 si retorn demà és positiu, 0 si no)\n# - Lags (retards dels retorns)\n# - Mitjana mòbil i desviació típica (rolling)\n\n\nfor asset in assets:\n    close_col = f'{asset}.Close'\n    volume_col = f'{asset}.Volume'\n\n    if close_col in df.columns and volume_col in df.columns:\n        # Retorn diari\n        df_features[f'{asset}_return'] = df[close_col].pct_change()\n\n        # Variable objectiu: retorn del dia següent\n        df_features[f'{asset}_target'] = (df_features[f'{asset}_return'].shift(-1) > 0).astype(int)\n\n        # Lags\n        df_features[f'{asset}_lag1'] = df_features[f'{asset}_return'].shift(1)\n        df_features[f'{asset}_lag2'] = df_features[f'{asset}_return'].shift(2)\n\n        # Mitjana mòbil i desviació\n        df_features[f'{asset}_ma5'] = df[close_col].rolling(5).mean()\n        df_features[f'{asset}_std5'] = df[close_col].rolling(5).std()\n\n        # Z-score del volum\n        df_features[f'{asset}_volume_z'] = (\n            (df[volume_col] - df[volume_col].rolling(20).mean()) /\n            df[volume_col].rolling(20).std()\n        )\n\n## Eliminem només les files amb valors nuls a qualsevol columna creada\ndf_clean = df_features.dropna()\n\n# Mostrem les dimensions resultants\nprint(f\"Número total d'actius: {len(assets)}\")\nprint(f\"Dimensions del df_clean: {df_clean.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:36:58.545122Z","iopub.execute_input":"2025-05-30T17:36:58.545507Z","iopub.status.idle":"2025-05-30T17:36:58.672827Z","shell.execute_reply.started":"2025-05-30T17:36:58.545480Z","shell.execute_reply":"2025-05-30T17:36:58.671425Z"}},"outputs":[{"name":"stdout","text":"Número total d'actius: 21\nDimensions del df_clean: (2, 275)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"df_clean_dict = {}\nassets_valids = []\n\nfor asset in assets:\n    relevant_cols = [f'{asset}_return', f'{asset}_target', f'{asset}_lag1',\n                     f'{asset}_lag2', f'{asset}_ma5', f'{asset}_std5', f'{asset}_volume_z']\n\n    if all(col in df_features.columns for col in relevant_cols):\n        df_asset = df_features[relevant_cols].dropna()\n        num_files_valides = len(df_asset)\n\n        if num_files_valides >= 1900:\n            df_clean_dict[asset] = df_asset\n            assets_valids.append(asset)\n            print(f\"{asset}: {num_files_valides} files vàlides (✔)\")\n        else:\n            print(f\"{asset}: {num_files_valides} files vàlides (✘)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:37:01.364192Z","iopub.execute_input":"2025-05-30T17:37:01.364581Z","iopub.status.idle":"2025-05-30T17:37:01.423508Z","shell.execute_reply.started":"2025-05-30T17:37:01.364554Z","shell.execute_reply":"2025-05-30T17:37:01.422357Z"}},"outputs":[{"name":"stdout","text":"AAPL: 1987 files vàlides (✔)\nAMS: 1987 files vàlides (✔)\nAMZN: 1987 files vàlides (✔)\nBBVA: 1987 files vàlides (✔)\nCABK: 211 files vàlides (✘)\nCLNX: 2 files vàlides (✘)\nFER: 1457 files vàlides (✘)\nGOOGL: 1987 files vàlides (✔)\nGSPC: 1987 files vàlides (✔)\nIBE: 17 files vàlides (✘)\nIBEX: 3227 files vàlides (✔)\nITX: 49 files vàlides (✘)\nIXIC: 1987 files vàlides (✔)\nJPM: 1987 files vàlides (✔)\nLLY: 1987 files vàlides (✔)\nMETA: 1667 files vàlides (✘)\nMSFT: 1987 files vàlides (✔)\nNVDA: 1987 files vàlides (✔)\nSAN: 1987 files vàlides (✔)\nTEF: 1987 files vàlides (✔)\nTSLA: 1928 files vàlides (✔)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"\n\nwarnings.filterwarnings(\"ignore\")\n\n# Definim el grid de paràmetres\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [3, 5, 10, None],\n    'min_samples_split': [2, 5, 10]\n}\n\n# Validació creuada estratificada\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nresults = []\n\nfor asset in assets_valids:\n    df_asset = df_clean_dict[asset]\n    X = df_asset.drop(columns=[f'{asset}_target'])\n    y = df_asset[f'{asset}_target']\n\n    # Divisió en train/test\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, stratify=y, test_size=0.2, random_state=42\n    )\n\n    # Grid search amb Random Forest\n    clf = RandomForestClassifier(random_state=42)\n    grid = GridSearchCV(clf, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n    grid.fit(X_train, y_train)\n\n    # Millor model i prediccions\n    best_model = grid.best_estimator_\n    y_pred = best_model.predict(X_test)\n    y_proba = best_model.predict_proba(X_test)[:, 1]\n\n    # Mètriques\n    roc = roc_auc_score(y_test, y_proba)\n    acc = accuracy_score(y_test, y_pred)\n    cm = confusion_matrix(y_test, y_pred)\n\n    results.append({\n        'asset': asset,\n        'roc_auc': roc,\n        'accuracy': acc,\n        'conf_matrix': cm,\n        'best_params': grid.best_params_\n    })\n\n# Mostrem resultats\nresults_df_rf = pd.DataFrame(results)#.sort_values(by='roc_auc', ascending=False)\nresults_df_rf\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:19:48.536254Z","iopub.execute_input":"2025-05-30T17:19:48.536715Z","iopub.status.idle":"2025-05-30T17:28:37.864203Z","shell.execute_reply.started":"2025-05-30T17:19:48.536674Z","shell.execute_reply":"2025-05-30T17:28:37.862912Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    asset   roc_auc  accuracy              conf_matrix  \\\n0    AAPL  0.530486  0.522613    [[98, 98], [92, 110]]   \n1     AMS  0.589062  0.595477   [[212, 24], [137, 25]]   \n2    AMZN  0.467708  0.472362   [[69, 125], [85, 119]]   \n3    BBVA  0.495289  0.507538   [[154, 56], [140, 48]]   \n4   GOOGL  0.507387  0.497487   [[104, 97], [103, 94]]   \n5    GSPC  0.533105  0.532663   [[65, 123], [63, 147]]   \n6    IBEX  0.491453  0.509288   [[80, 234], [83, 249]]   \n7    IXIC  0.488088  0.525126   [[67, 120], [69, 142]]   \n8     JPM  0.479381  0.467337  [[103, 101], [111, 83]]   \n9     LLY  0.515054  0.494975   [[73, 123], [78, 124]]   \n10   MSFT  0.516313  0.515075   [[89, 109], [84, 116]]   \n11   NVDA  0.465194  0.500000   [[97, 97], [102, 102]]   \n12    SAN  0.470734  0.474874   [[139, 73], [136, 50]]   \n13    TEF  0.545337  0.535176   [[142, 71], [114, 71]]   \n14   TSLA  0.461210  0.463731   [[128, 71], [136, 51]]   \n\n                                          best_params  \n0   {'max_depth': 10, 'min_samples_split': 5, 'n_e...  \n1   {'max_depth': 5, 'min_samples_split': 2, 'n_es...  \n2   {'max_depth': 5, 'min_samples_split': 5, 'n_es...  \n3   {'max_depth': 5, 'min_samples_split': 2, 'n_es...  \n4   {'max_depth': 10, 'min_samples_split': 10, 'n_...  \n5   {'max_depth': 10, 'min_samples_split': 2, 'n_e...  \n6   {'max_depth': 3, 'min_samples_split': 2, 'n_es...  \n7   {'max_depth': None, 'min_samples_split': 5, 'n...  \n8   {'max_depth': 10, 'min_samples_split': 10, 'n_...  \n9   {'max_depth': 3, 'min_samples_split': 2, 'n_es...  \n10  {'max_depth': 3, 'min_samples_split': 10, 'n_e...  \n11  {'max_depth': None, 'min_samples_split': 2, 'n...  \n12  {'max_depth': 10, 'min_samples_split': 10, 'n_...  \n13  {'max_depth': None, 'min_samples_split': 5, 'n...  \n14  {'max_depth': 5, 'min_samples_split': 5, 'n_es...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asset</th>\n      <th>roc_auc</th>\n      <th>accuracy</th>\n      <th>conf_matrix</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAPL</td>\n      <td>0.530486</td>\n      <td>0.522613</td>\n      <td>[[98, 98], [92, 110]]</td>\n      <td>{'max_depth': 10, 'min_samples_split': 5, 'n_e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AMS</td>\n      <td>0.589062</td>\n      <td>0.595477</td>\n      <td>[[212, 24], [137, 25]]</td>\n      <td>{'max_depth': 5, 'min_samples_split': 2, 'n_es...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AMZN</td>\n      <td>0.467708</td>\n      <td>0.472362</td>\n      <td>[[69, 125], [85, 119]]</td>\n      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_es...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BBVA</td>\n      <td>0.495289</td>\n      <td>0.507538</td>\n      <td>[[154, 56], [140, 48]]</td>\n      <td>{'max_depth': 5, 'min_samples_split': 2, 'n_es...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GOOGL</td>\n      <td>0.507387</td>\n      <td>0.497487</td>\n      <td>[[104, 97], [103, 94]]</td>\n      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GSPC</td>\n      <td>0.533105</td>\n      <td>0.532663</td>\n      <td>[[65, 123], [63, 147]]</td>\n      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>IBEX</td>\n      <td>0.491453</td>\n      <td>0.509288</td>\n      <td>[[80, 234], [83, 249]]</td>\n      <td>{'max_depth': 3, 'min_samples_split': 2, 'n_es...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>IXIC</td>\n      <td>0.488088</td>\n      <td>0.525126</td>\n      <td>[[67, 120], [69, 142]]</td>\n      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>JPM</td>\n      <td>0.479381</td>\n      <td>0.467337</td>\n      <td>[[103, 101], [111, 83]]</td>\n      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LLY</td>\n      <td>0.515054</td>\n      <td>0.494975</td>\n      <td>[[73, 123], [78, 124]]</td>\n      <td>{'max_depth': 3, 'min_samples_split': 2, 'n_es...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>MSFT</td>\n      <td>0.516313</td>\n      <td>0.515075</td>\n      <td>[[89, 109], [84, 116]]</td>\n      <td>{'max_depth': 3, 'min_samples_split': 10, 'n_e...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NVDA</td>\n      <td>0.465194</td>\n      <td>0.500000</td>\n      <td>[[97, 97], [102, 102]]</td>\n      <td>{'max_depth': None, 'min_samples_split': 2, 'n...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>SAN</td>\n      <td>0.470734</td>\n      <td>0.474874</td>\n      <td>[[139, 73], [136, 50]]</td>\n      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>TEF</td>\n      <td>0.545337</td>\n      <td>0.535176</td>\n      <td>[[142, 71], [114, 71]]</td>\n      <td>{'max_depth': None, 'min_samples_split': 5, 'n...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>TSLA</td>\n      <td>0.461210</td>\n      <td>0.463731</td>\n      <td>[[128, 71], [136, 51]]</td>\n      <td>{'max_depth': 5, 'min_samples_split': 5, 'n_es...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# XGBOOST\n\n\nresults = []\n\n# Paràmetres per fer grid search\nparam_grid = {\n    'max_depth': [3, 5, 10],\n    'n_estimators': [50, 100],\n    'learning_rate': [0.01, 0.1]\n}\n\nfor asset in assets_valids:\n    X_cols = [col for col in df_features.columns if col.startswith(asset) and col != f'{asset}_target']\n    y_col = f'{asset}_target'\n\n    df_model = df_features[X_cols + [y_col]].dropna()\n    \n    if len(df_model) < 1900:\n        continue  # Saltar si no hi ha prou dades\n\n    X = df_model[X_cols]\n    y = df_model[y_col]\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n\n    model = XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n\n    grid = GridSearchCV(model, param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n    grid.fit(X_train, y_train)\n\n    best_model = grid.best_estimator_\n    y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n    y_pred = (y_pred_prob > 0.5).astype(int)\n\n    roc_auc = roc_auc_score(y_test, y_pred_prob)\n    accuracy = accuracy_score(y_test, y_pred)\n    conf_matrix = confusion_matrix(y_test, y_pred)\n\n    results.append({\n        'asset': asset,\n        'roc_auc': roc_auc,\n        'accuracy': accuracy,\n        'conf_matrix': conf_matrix.tolist(),\n        'best_params': grid.best_params_\n    })\n\n# Convertir resultats a DataFrame\nresults_df_xgb = pd.DataFrame(results)\nresults_df_xgb.sort_values(by='roc_auc', ascending=False, inplace=True)\nresults_df_xgb.reset_index(drop=True, inplace=True)\n\nresults_df_xgb.head(10)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:28:37.865466Z","iopub.execute_input":"2025-05-30T17:28:37.865793Z","iopub.status.idle":"2025-05-30T17:29:34.347068Z","shell.execute_reply.started":"2025-05-30T17:28:37.865765Z","shell.execute_reply":"2025-05-30T17:29:34.345975Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   asset   roc_auc  accuracy               conf_matrix  \\\n0    AMS  0.592133  0.592965    [[298, 56], [187, 56]]   \n1   GSPC  0.522571  0.514238  [[129, 153], [137, 178]]   \n2   NVDA  0.516183  0.499162  [[139, 152], [147, 159]]   \n3  GOOGL  0.514339  0.505863  [[161, 141], [154, 141]]   \n4   IXIC  0.508100  0.517588  [[114, 166], [122, 195]]   \n5   AAPL  0.493276  0.489112  [[140, 155], [150, 152]]   \n6   IBEX  0.488428  0.515996    [[54, 418], [51, 446]]   \n7   MSFT  0.487868  0.479062  [[138, 159], [152, 148]]   \n8    TEF  0.487483  0.482412   [[189, 130], [179, 99]]   \n9   BBVA  0.487402  0.499162    [[215, 99], [200, 83]]   \n\n                                         best_params  \n0  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...  \n1  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  \n2  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  \n3  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...  \n4  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  \n5  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  \n6  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...  \n7  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...  \n8  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...  \n9  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asset</th>\n      <th>roc_auc</th>\n      <th>accuracy</th>\n      <th>conf_matrix</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AMS</td>\n      <td>0.592133</td>\n      <td>0.592965</td>\n      <td>[[298, 56], [187, 56]]</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GSPC</td>\n      <td>0.522571</td>\n      <td>0.514238</td>\n      <td>[[129, 153], [137, 178]]</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NVDA</td>\n      <td>0.516183</td>\n      <td>0.499162</td>\n      <td>[[139, 152], [147, 159]]</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GOOGL</td>\n      <td>0.514339</td>\n      <td>0.505863</td>\n      <td>[[161, 141], [154, 141]]</td>\n      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IXIC</td>\n      <td>0.508100</td>\n      <td>0.517588</td>\n      <td>[[114, 166], [122, 195]]</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AAPL</td>\n      <td>0.493276</td>\n      <td>0.489112</td>\n      <td>[[140, 155], [150, 152]]</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>IBEX</td>\n      <td>0.488428</td>\n      <td>0.515996</td>\n      <td>[[54, 418], [51, 446]]</td>\n      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>MSFT</td>\n      <td>0.487868</td>\n      <td>0.479062</td>\n      <td>[[138, 159], [152, 148]]</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>TEF</td>\n      <td>0.487483</td>\n      <td>0.482412</td>\n      <td>[[189, 130], [179, 99]]</td>\n      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>BBVA</td>\n      <td>0.487402</td>\n      <td>0.499162</td>\n      <td>[[215, 99], [200, 83]]</td>\n      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#Regressión logistica\n\nfeature_suffixes = [\"_lag1\", \"_lag2\", \"_ma5\", \"_std5\", \"_volume_z\"]\nresults = []\n\nfor asset in assets_valids:\n    feature_cols = [f\"{asset}{suffix}\" for suffix in feature_suffixes]\n    target_col = f\"{asset}_target\"\n\n    # Verifiquem que existeixin totes les columnes necessàries\n    if all(col in df_features.columns for col in feature_cols + [target_col]):\n        df_model = df_features[feature_cols + [target_col]].dropna()\n        X = df_model[feature_cols]\n        y = df_model[target_col]\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n        # Grid search amb regularització\n        param_grid = {\n            'C': [0.01, 0.1, 1, 10, 100],\n            'penalty': ['l1', 'l2'],\n            'solver': ['liblinear']  # liblinear suporta l1 i l2\n        }\n        model = GridSearchCV(LogisticRegression(), param_grid, cv=3, scoring='roc_auc')\n        model.fit(X_train, y_train)\n\n        y_pred = model.predict(X_test)\n        y_proba = model.predict_proba(X_test)[:, 1]\n\n        roc_auc = roc_auc_score(y_test, y_proba)\n        accuracy = accuracy_score(y_test, y_pred)\n        conf_matrix = confusion_matrix(y_test, y_pred)\n        best_params = model.best_params_\n\n        results.append({\n            \"asset\": asset,\n            \"roc_auc\": roc_auc,\n            \"accuracy\": accuracy,\n            \"conf_matrix\": conf_matrix.tolist(),\n            \"best_params\": best_params\n        })\n\nresults_df_log = pd.DataFrame(results)\nresults_df_log.sort_values(\"roc_auc\", ascending=False, inplace=True)\nresults_df_log.reset_index(drop=True, inplace=True)\nresults_df_log.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:29:34.349671Z","iopub.execute_input":"2025-05-30T17:29:34.349984Z","iopub.status.idle":"2025-05-30T17:29:38.726419Z","shell.execute_reply.started":"2025-05-30T17:29:34.349960Z","shell.execute_reply":"2025-05-30T17:29:38.725308Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   asset   roc_auc  accuracy             conf_matrix  \\\n0    JPM  0.576672  0.562814  [[106, 82], [92, 118]]   \n1    TEF  0.535266  0.555276    [[217, 4], [173, 4]]   \n2   BBVA  0.534933  0.487437    [[194, 0], [204, 0]]   \n3    LLY  0.523665  0.522613  [[14, 178], [12, 194]]   \n4   IXIC  0.520177  0.502513    [[9, 191], [7, 191]]   \n5   GSPC  0.519736  0.494975    [[0, 201], [0, 197]]   \n6   MSFT  0.518232  0.500000    [[0, 199], [0, 199]]   \n7   NVDA  0.512634  0.512563    [[0, 194], [0, 204]]   \n8  GOOGL  0.512563  0.502513    [[0, 198], [0, 200]]   \n9    AMS  0.503103  0.542714    [[216, 0], [182, 0]]   \n\n                                         best_params  \n0   {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  \n1  {'C': 100, 'penalty': 'l1', 'solver': 'libline...  \n2  {'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...  \n3  {'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...  \n4  {'C': 100, 'penalty': 'l1', 'solver': 'libline...  \n5   {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  \n6  {'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...  \n7  {'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...  \n8  {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...  \n9  {'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asset</th>\n      <th>roc_auc</th>\n      <th>accuracy</th>\n      <th>conf_matrix</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JPM</td>\n      <td>0.576672</td>\n      <td>0.562814</td>\n      <td>[[106, 82], [92, 118]]</td>\n      <td>{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEF</td>\n      <td>0.535266</td>\n      <td>0.555276</td>\n      <td>[[217, 4], [173, 4]]</td>\n      <td>{'C': 100, 'penalty': 'l1', 'solver': 'libline...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BBVA</td>\n      <td>0.534933</td>\n      <td>0.487437</td>\n      <td>[[194, 0], [204, 0]]</td>\n      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LLY</td>\n      <td>0.523665</td>\n      <td>0.522613</td>\n      <td>[[14, 178], [12, 194]]</td>\n      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IXIC</td>\n      <td>0.520177</td>\n      <td>0.502513</td>\n      <td>[[9, 191], [7, 191]]</td>\n      <td>{'C': 100, 'penalty': 'l1', 'solver': 'libline...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GSPC</td>\n      <td>0.519736</td>\n      <td>0.494975</td>\n      <td>[[0, 201], [0, 197]]</td>\n      <td>{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MSFT</td>\n      <td>0.518232</td>\n      <td>0.500000</td>\n      <td>[[0, 199], [0, 199]]</td>\n      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NVDA</td>\n      <td>0.512634</td>\n      <td>0.512563</td>\n      <td>[[0, 194], [0, 204]]</td>\n      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>GOOGL</td>\n      <td>0.512563</td>\n      <td>0.502513</td>\n      <td>[[0, 198], [0, 200]]</td>\n      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'libline...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>AMS</td>\n      <td>0.503103</td>\n      <td>0.542714</td>\n      <td>[[216, 0], [182, 0]]</td>\n      <td>{'C': 0.01, 'penalty': 'l1', 'solver': 'liblin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensemble de los 3 modelos (RF, XGB, LOG)\n\n\n\nensemble_results = []\n\nfor asset in assets_valids:\n    X_cols = [col for col in df_features.columns if col.startswith(asset) and col != f'{asset}_target']\n    y_col = f'{asset}_target'\n\n    df_model = df_features[X_cols + [y_col]].dropna() \n   \n    X = df_model[X_cols]\n    y = df_model[y_col]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n\n    # Models base\n    rf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)\n    xgb = XGBClassifier(n_estimators=50, max_depth=5, use_label_encoder=False, eval_metric='logloss', random_state=42)\n    logreg = LogisticRegression(max_iter=1000, random_state=42)\n\n    # Stacking ensemble\n    stack = StackingClassifier(\n        estimators=[\n            ('rf', rf),\n            ('xgb', xgb),\n            ('logreg', logreg)\n        ],\n        final_estimator=LogisticRegression(),\n        passthrough=False,\n        cv=5\n    )\n\n    # Entrenament\n    stack.fit(X_train, y_train)\n    y_pred = stack.predict(X_test)\n    y_proba = stack.predict_proba(X_test)[:, 1]\n\n    # Mètriques\n    acc = accuracy_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_proba)\n    cm = confusion_matrix(y_test, y_pred)\n\n    ensemble_results.append({\n        'asset': asset,\n        'roc_auc': roc,\n        'accuracy': acc,\n        'conf_matrix': cm.tolist()\n    })\n\nensemble_results_df = pd.DataFrame(ensemble_results)\nensemble_results_df.sort_values(by='roc_auc', ascending=False, inplace=True)\nensemble_results_df.reset_index(drop=True, inplace=True)\nensemble_results_df.head()\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:29:38.727668Z","iopub.execute_input":"2025-05-30T17:29:38.727973Z","iopub.status.idle":"2025-05-30T17:30:09.186453Z","shell.execute_reply.started":"2025-05-30T17:29:38.727948Z","shell.execute_reply":"2025-05-30T17:30:09.185290Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   asset   roc_auc  accuracy             conf_matrix\n0    JPM  0.564488  0.515075  [[161, 27], [166, 44]]\n1   NVDA  0.539393  0.535176  [[80, 114], [71, 133]]\n2    TEF  0.537490  0.552764    [[220, 1], [177, 0]]\n3   GSPC  0.523474  0.494975    [[0, 201], [0, 197]]\n4  GOOGL  0.518535  0.512563  [[131, 67], [127, 73]]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asset</th>\n      <th>roc_auc</th>\n      <th>accuracy</th>\n      <th>conf_matrix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JPM</td>\n      <td>0.564488</td>\n      <td>0.515075</td>\n      <td>[[161, 27], [166, 44]]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NVDA</td>\n      <td>0.539393</td>\n      <td>0.535176</td>\n      <td>[[80, 114], [71, 133]]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEF</td>\n      <td>0.537490</td>\n      <td>0.552764</td>\n      <td>[[220, 1], [177, 0]]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GSPC</td>\n      <td>0.523474</td>\n      <td>0.494975</td>\n      <td>[[0, 201], [0, 197]]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GOOGL</td>\n      <td>0.518535</td>\n      <td>0.512563</td>\n      <td>[[131, 67], [127, 73]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#SVM\n\nX_dict = {}\ny_dict = {}\nX_train_dict = {}\nX_test_dict = {}\ny_train_dict = {}\ny_test_dict = {}\n\n\nfor asset in assets_valids:\n    # Variables predictives (són les mateixes que has fet servir abans)\n    feature_cols = [\n        f'{asset}_lag1', f'{asset}_lag2',\n        f'{asset}_ma5', f'{asset}_std5',\n        f'{asset}_volume_z'\n    ]\n    target_col = f'{asset}_target'\n\n    # Comprovem que les columnes existeixen i no tenen valors nuls\n    if all(col in df_clean.columns for col in feature_cols + [target_col]):\n        df_asset = df_clean[feature_cols + [target_col]].dropna()\n\n        X = df_asset[feature_cols]\n        y = df_asset[target_col]\n\n        # Guardem a X_dict i y_dict\n        X_dict[asset] = X\n        y_dict[asset] = y\n\n        # Split train/test\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, test_size=0.2, shuffle=False\n        )\n\n        X_train_dict[asset] = X_train\n        X_test_dict[asset] = X_test\n        y_train_dict[asset] = y_train\n        y_test_dict[asset] = y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:30:09.187461Z","iopub.execute_input":"2025-05-30T17:30:09.187749Z","iopub.status.idle":"2025-05-30T17:30:09.252595Z","shell.execute_reply.started":"2025-05-30T17:30:09.187725Z","shell.execute_reply":"2025-05-30T17:30:09.251359Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\n#param_grid = {\n#    'C': [0.1, 1, 10],\n#    'kernel': ['linear', 'rbf'],\n#    'gamma': ['scale', 'auto']\n#}\n\n#results = {}\n\n#for asset in assets_valids:\n#    df_asset = df_clean_dict[asset]\n#    \n#    X = df_asset.drop(columns=[f'{asset}_target'])\n#    y = df_asset[f'{asset}_target']\n#\n#    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n#\n#    print(f\"{asset} - Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n#\n#    if len(X_train) < 3:\n#        print(f\"Skipping {asset} due to too few training samples\")\n#        continue\n#\n#    grid = GridSearchCV(SVC(probability=True), param_grid, cv=3, scoring='roc_auc')\n#    grid.fit(X_train, y_train)\n#\n#    best_model = grid.best_estimator_\n#    y_pred = best_model.predict(X_test)\n#    y_proba = best_model.predict_proba(X_test)[:, 1]\n#\n#    from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n#\n#    roc_auc = roc_auc_score(y_test, y_proba)\n#    accuracy = accuracy_score(y_test, y_pred)\n#    conf_mat = confusion_matrix(y_test, y_pred)\n#\n#    results[asset] = {\n#        'roc_auc': roc_auc,\n#        'accuracy': accuracy,\n#        'conf_matrix': conf_mat,\n#        'best_params': grid.best_params_\n#    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:30:09.253765Z","iopub.execute_input":"2025-05-30T17:30:09.254255Z","iopub.status.idle":"2025-05-30T17:30:09.283529Z","shell.execute_reply.started":"2025-05-30T17:30:09.254205Z","shell.execute_reply":"2025-05-30T17:30:09.282184Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\n\nnn_results = []\n\nfor asset in assets_valids:\n    X_cols = [col for col in df_clean_dict[asset].columns if col != f'{asset}_target']\n    y_col = f'{asset}_target'\n\n    df_model = df_clean_dict[asset]\n\n    X = df_model[X_cols].values\n    y = df_model[y_col].values\n\n    # Escalat\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # Divisió en train/test\n    split_index = int(len(X_scaled) * 0.8)\n    X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]\n    y_train, y_test = y[:split_index], y[split_index:]\n\n    # Model de xarxa neuronal\n    model = Sequential([\n        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n        Dropout(0.3),\n        Dense(32, activation='relu'),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    # Entrenament\n    model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0)\n\n    # Avaluació\n    y_proba = model.predict(X_test).flatten()\n    y_pred = (y_proba > 0.5).astype(int)\n\n    acc = accuracy_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_proba)\n    cm = confusion_matrix(y_test, y_pred)\n\n    nn_results.append({\n        'asset': asset,\n        'roc_auc': roc,\n        'accuracy': acc,\n        'conf_matrix': cm.tolist()\n    })\n\n# Resultats\nnn_results_df = pd.DataFrame(nn_results)\nnn_results_df.sort_values(by='roc_auc', ascending=False, inplace=True)\nnn_results_df.reset_index(drop=True, inplace=True)\nnn_results_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:42:42.566805Z","iopub.execute_input":"2025-05-30T17:42:42.567489Z","iopub.status.idle":"2025-05-30T17:43:56.661176Z","shell.execute_reply.started":"2025-05-30T17:42:42.567453Z","shell.execute_reply":"2025-05-30T17:43:56.659904Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   asset   roc_auc  accuracy             conf_matrix\n0    AMS  0.585368  0.552764   [[208, 8], [170, 12]]\n1    LLY  0.563714  0.540201  [[68, 124], [59, 147]]\n2  GOOGL  0.560606  0.545226  [[60, 138], [43, 157]]\n3   AAPL  0.545489  0.522613  [[47, 155], [35, 161]]\n4   AMZN  0.534123  0.530151  [[36, 166], [21, 175]]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asset</th>\n      <th>roc_auc</th>\n      <th>accuracy</th>\n      <th>conf_matrix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AMS</td>\n      <td>0.585368</td>\n      <td>0.552764</td>\n      <td>[[208, 8], [170, 12]]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LLY</td>\n      <td>0.563714</td>\n      <td>0.540201</td>\n      <td>[[68, 124], [59, 147]]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GOOGL</td>\n      <td>0.560606</td>\n      <td>0.545226</td>\n      <td>[[60, 138], [43, 157]]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAPL</td>\n      <td>0.545489</td>\n      <td>0.522613</td>\n      <td>[[47, 155], [35, 161]]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AMZN</td>\n      <td>0.534123</td>\n      <td>0.530151</td>\n      <td>[[36, 166], [21, 175]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"\n\nlstm_results = []\n\nsequence_length = 10  # n dies consecutius com a entrada\n\nfor asset in assets_valids:\n    df = df_clean_dict[asset]\n    \n    X_cols = [col for col in df.columns if col != f'{asset}_target']\n    y_col = f'{asset}_target'\n\n    # Convertir a arrays\n    X = df[X_cols].values\n    y = df[y_col].values\n\n    # Escalat\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # Crear seqüències\n    X_seq, y_seq = [], []\n    for i in range(len(X_scaled) - sequence_length):\n        X_seq.append(X_scaled[i:i + sequence_length])\n        y_seq.append(y[i + sequence_length])\n\n    X_seq = np.array(X_seq)\n    y_seq = np.array(y_seq)\n\n    # Dividir en train/test (80/20)\n    split = int(len(X_seq) * 0.8)\n    X_train, X_test = X_seq[:split], X_seq[split:]\n    y_train, y_test = y_seq[:split], y_seq[split:]\n\n    # Model LSTM\n    model = Sequential([\n        LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n        Dropout(0.3),\n        Dense(32, activation='relu'),\n        Dropout(0.2),\n        Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    # Entrenament\n    model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=0)\n\n    # Prediccions\n    y_proba = model.predict(X_test).flatten()\n    y_pred = (y_proba > 0.5).astype(int)\n\n    # Mètriques\n    acc = accuracy_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_proba)\n    cm = confusion_matrix(y_test, y_pred)\n\n    lstm_results.append({\n        'asset': asset,\n        'roc_auc': roc,\n        'accuracy': acc,\n        'conf_matrix': cm.tolist()\n    })\n\n# Resultats\nlstm_results_df = pd.DataFrame(lstm_results)\nlstm_results_df.sort_values(by='roc_auc', ascending=False, inplace=True)\nlstm_results_df.reset_index(drop=True, inplace=True)\nlstm_results_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T17:48:28.715017Z","iopub.execute_input":"2025-05-30T17:48:28.715456Z","iopub.status.idle":"2025-05-30T17:51:50.655524Z","shell.execute_reply.started":"2025-05-30T17:48:28.715425Z","shell.execute_reply":"2025-05-30T17:51:50.654272Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   asset   roc_auc  accuracy              conf_matrix\n0    LLY  0.557036  0.547980   [[35, 157], [22, 182]]\n1  GOOGL  0.538760  0.525253   [[97, 100], [88, 111]]\n2   AMZN  0.512602  0.522727   [[74, 126], [63, 133]]\n3   BBVA  0.500038  0.492424   [[126, 67], [134, 69]]\n4    JPM  0.490180  0.472222  [[81, 107], [102, 106]]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asset</th>\n      <th>roc_auc</th>\n      <th>accuracy</th>\n      <th>conf_matrix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LLY</td>\n      <td>0.557036</td>\n      <td>0.547980</td>\n      <td>[[35, 157], [22, 182]]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GOOGL</td>\n      <td>0.538760</td>\n      <td>0.525253</td>\n      <td>[[97, 100], [88, 111]]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AMZN</td>\n      <td>0.512602</td>\n      <td>0.522727</td>\n      <td>[[74, 126], [63, 133]]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BBVA</td>\n      <td>0.500038</td>\n      <td>0.492424</td>\n      <td>[[126, 67], [134, 69]]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JPM</td>\n      <td>0.490180</td>\n      <td>0.472222</td>\n      <td>[[81, 107], [102, 106]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"\n#LSTM amb majos sequence_length\nlstm_results_2 = []\n\nsequence_length = 30  # n dies consecutius com a entrada\n\nfor asset in assets_valids:\n    df = df_clean_dict[asset]\n    \n    X_cols = [col for col in df.columns if col != f'{asset}_target']\n    y_col = f'{asset}_target'\n\n    # Convertir a arrays\n    X = df[X_cols].values\n    y = df[y_col].values\n\n    # Escalat\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # Crear seqüències\n    X_seq, y_seq = [], []\n    for i in range(len(X_scaled) - sequence_length):\n        X_seq.append(X_scaled[i:i + sequence_length])\n        y_seq.append(y[i + sequence_length])\n\n    X_seq = np.array(X_seq)\n    y_seq = np.array(y_seq)\n\n    # Dividir en train/test (80/20)\n    split = int(len(X_seq) * 0.8)\n    X_train, X_test = X_seq[:split], X_seq[split:]\n    y_train, y_test = y_seq[:split], y_seq[split:]\n\n    # Model LSTM\n    model = Sequential([\n        LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n        Dropout(0.5),\n        Dense(32, activation='relu'),\n        Dropout(0.2),\n        Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    # Entrenament\n\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n    model = Sequential([\n        Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n        MaxPooling1D(pool_size=2),\n        LSTM(32),\n        Dropout(0.2),\n        Dense(1, activation='sigmoid')\n    ])\n\n    # Prediccions\n    y_proba = model.predict(X_test).flatten()\n    y_pred = (y_proba > 0.5).astype(int)\n\n    # Mètriques\n    acc = accuracy_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_proba)\n    cm = confusion_matrix(y_test, y_pred)\n\n    lstm_results_2.append({\n        'asset': asset,\n        'roc_auc': roc,\n        'accuracy': acc,\n        'conf_matrix': cm.tolist()\n    })\n\n# Resultats\nlstm_results_2_df = pd.DataFrame(lstm_results_2)\nlstm_results_2_df.sort_values(by='roc_auc', ascending=False, inplace=True)\nlstm_results_2_df.reset_index(drop=True, inplace=True)\nlstm_results_2_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:20:00.596776Z","iopub.execute_input":"2025-05-30T18:20:00.597163Z","iopub.status.idle":"2025-05-30T18:20:10.611787Z","shell.execute_reply.started":"2025-05-30T18:20:00.597133Z","shell.execute_reply":"2025-05-30T18:20:10.610590Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"  asset   roc_auc  accuracy             conf_matrix\n0  TSLA  0.563053  0.447368    [[0, 210], [0, 170]]\n1  MSFT  0.551442  0.505102    [[198, 0], [194, 0]]\n2   JPM  0.510753  0.477041  [[121, 65], [140, 66]]\n3   TEF  0.510042  0.556122  [[206, 14], [160, 12]]\n4  GSPC  0.503723  0.502551    [[197, 1], [194, 0]]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asset</th>\n      <th>roc_auc</th>\n      <th>accuracy</th>\n      <th>conf_matrix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TSLA</td>\n      <td>0.563053</td>\n      <td>0.447368</td>\n      <td>[[0, 210], [0, 170]]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MSFT</td>\n      <td>0.551442</td>\n      <td>0.505102</td>\n      <td>[[198, 0], [194, 0]]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JPM</td>\n      <td>0.510753</td>\n      <td>0.477041</td>\n      <td>[[121, 65], [140, 66]]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEF</td>\n      <td>0.510042</td>\n      <td>0.556122</td>\n      <td>[[206, 14], [160, 12]]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GSPC</td>\n      <td>0.503723</td>\n      <td>0.502551</td>\n      <td>[[197, 1], [194, 0]]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"\n#LSTM+CNN+Attention layer\n# Custom attention layer\ndef attention_layer(inputs):\n    # inputs.shape = (batch_size, time_steps, input_dim)\n    attention = Dense(1, activation='tanh')(inputs)                     # shape: (batch_size, time_steps, 1)\n    attention = tf.keras.layers.Flatten()(attention)                   # shape: (batch_size, time_steps)\n    attention = Activation('softmax')(attention)                       # softmax over time_steps\n    attention = tf.keras.layers.RepeatVector(inputs.shape[2])(attention)  # (batch_size, input_dim, time_steps)\n    attention = Permute([2, 1])(attention)                             # (batch_size, time_steps, input_dim)\n    weighted = Multiply()([inputs, attention])                         # (batch_size, time_steps, input_dim)\n    return Lambda(lambda x: K.sum(x, axis=1))(weighted)                # sum over time axis → (batch_size, input_dim)\n\n# Input\ninput_shape = (X_train.shape[1], X_train.shape[2])  # (sequence_length, num_features)\ninputs = Input(shape=input_shape)\n\n# CNN + LSTM + Attention\nx = Conv1D(64, kernel_size=3, activation='relu')(inputs)\nx = MaxPooling1D(pool_size=2)(x)\nx = LSTM(64, return_sequences=True)(x)\nx = Dropout(0.3)(x)\n\n# Attention\nx = attention_layer(x)  # Output: (batch_size, 64)\n\n# Final Dense\nx = Dense(32, activation='relu')(x)\nx = Dropout(0.2)(x)\noutputs = Dense(1, activation='sigmoid')(x)\n\n# Model\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Entrenament\nmodel.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=1)\n\n\ncnn_lstm_attention_results = []\n\n# Prediccions\ny_proba = model.predict(X_test).flatten()\ny_pred = (y_proba > 0.5).astype(int)\n\n# Mètriques\nacc = accuracy_score(y_test, y_pred)\nroc = roc_auc_score(y_test, y_proba)\ncm = confusion_matrix(y_test, y_pred)\n\ncnn_lstm_attention_results.append({\n    'asset': asset,\n    'roc_auc': roc,\n    'accuracy': acc,\n    'conf_matrix': cm.tolist()\n})\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:24:46.242082Z","iopub.execute_input":"2025-05-30T18:24:46.242470Z","iopub.status.idle":"2025-05-30T18:25:06.384645Z","shell.execute_reply.started":"2025-05-30T18:24:46.242444Z","shell.execute_reply":"2025-05-30T18:25:06.383533Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5174 - loss: 0.6926 - val_accuracy: 0.5296 - val_loss: 0.6933\nEpoch 2/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5234 - loss: 0.6925 - val_accuracy: 0.4638 - val_loss: 0.6948\nEpoch 3/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4915 - loss: 0.6942 - val_accuracy: 0.4539 - val_loss: 0.6959\nEpoch 4/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5374 - loss: 0.6915 - val_accuracy: 0.4507 - val_loss: 0.6964\nEpoch 5/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4974 - loss: 0.6937 - val_accuracy: 0.4474 - val_loss: 0.7079\nEpoch 6/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5174 - loss: 0.6927 - val_accuracy: 0.4474 - val_loss: 0.7044\nEpoch 7/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5150 - loss: 0.6937 - val_accuracy: 0.4474 - val_loss: 0.6992\nEpoch 8/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5361 - loss: 0.6906 - val_accuracy: 0.4638 - val_loss: 0.6950\nEpoch 9/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5263 - loss: 0.6917 - val_accuracy: 0.5000 - val_loss: 0.6935\nEpoch 10/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5410 - loss: 0.6917 - val_accuracy: 0.5559 - val_loss: 0.6894\nEpoch 11/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5247 - loss: 0.6926 - val_accuracy: 0.4474 - val_loss: 0.7002\nEpoch 12/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5201 - loss: 0.6920 - val_accuracy: 0.4704 - val_loss: 0.6989\nEpoch 13/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5027 - loss: 0.6944 - val_accuracy: 0.4408 - val_loss: 0.7063\nEpoch 14/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5125 - loss: 0.6935 - val_accuracy: 0.4375 - val_loss: 0.7071\nEpoch 15/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5259 - loss: 0.6919 - val_accuracy: 0.5296 - val_loss: 0.6932\nEpoch 16/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5129 - loss: 0.6913 - val_accuracy: 0.4803 - val_loss: 0.7002\nEpoch 17/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5108 - loss: 0.6937 - val_accuracy: 0.5164 - val_loss: 0.6947\nEpoch 18/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5335 - loss: 0.6906 - val_accuracy: 0.5033 - val_loss: 0.6949\nEpoch 19/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5372 - loss: 0.6903 - val_accuracy: 0.4539 - val_loss: 0.7038\nEpoch 20/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5285 - loss: 0.6900 - val_accuracy: 0.4539 - val_loss: 0.7130\nEpoch 21/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5219 - loss: 0.6879 - val_accuracy: 0.5132 - val_loss: 0.6988\nEpoch 22/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5213 - loss: 0.6907 - val_accuracy: 0.4934 - val_loss: 0.7007\nEpoch 23/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5340 - loss: 0.6893 - val_accuracy: 0.5296 - val_loss: 0.7019\nEpoch 24/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5402 - loss: 0.6946 - val_accuracy: 0.4539 - val_loss: 0.7219\nEpoch 25/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5141 - loss: 0.6944 - val_accuracy: 0.4408 - val_loss: 0.7422\nEpoch 26/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5340 - loss: 0.6883 - val_accuracy: 0.4375 - val_loss: 0.7576\nEpoch 27/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5187 - loss: 0.6856 - val_accuracy: 0.4605 - val_loss: 0.7777\nEpoch 28/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5213 - loss: 0.6899 - val_accuracy: 0.5230 - val_loss: 0.6952\nEpoch 29/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5344 - loss: 0.6912 - val_accuracy: 0.4605 - val_loss: 0.7060\nEpoch 30/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5202 - loss: 0.6927 - val_accuracy: 0.4901 - val_loss: 0.7323\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"y_train.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:27:11.962825Z","iopub.execute_input":"2025-05-30T18:27:11.963181Z","iopub.status.idle":"2025-05-30T18:27:11.969839Z","shell.execute_reply.started":"2025-05-30T18:27:11.963154Z","shell.execute_reply":"2025-05-30T18:27:11.968576Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0.49341238471673254"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"## LSTM+ random forest\n\n# -------------------------------\n# 1. Defineix el model deep\n# -------------------------------\ndef attention_layer(inputs):\n    attention = Dense(1, activation='tanh')(inputs)\n    attention = tf.keras.layers.Flatten()(attention)\n    attention = Activation('softmax')(attention)\n    attention = tf.keras.layers.RepeatVector(inputs.shape[2])(attention)\n    attention = Permute([2, 1])(attention)\n    weighted = Multiply()([inputs, attention])\n    return Lambda(lambda x: K.sum(x, axis=1))(weighted)\n\ninput_shape = (X_train.shape[1], X_train.shape[2])  # (seq_len, num_features)\ninputs = Input(shape=input_shape)\n\nx = Conv1D(64, kernel_size=3, activation='relu')(inputs)\nx = MaxPooling1D(pool_size=2)(x)\nx = LSTM(64, return_sequences=True)(x)\nx = Dropout(0.3)(x)\n\nx = attention_layer(x)\nx = Dense(32, activation='relu', name='deep_features')(x)\nx = Dropout(0.2)(x)\noutputs = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# -------------------------------\n# 2. Entrenament\n# -------------------------------\nmodel.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=1)\n\n# -------------------------------\n# 3. Extracció de deep features\n# -------------------------------\nfeature_extractor = Model(inputs=model.input, outputs=model.get_layer('deep_features').output)\n\nX_train_feats = feature_extractor.predict(X_train)\nX_test_feats = feature_extractor.predict(X_test)\n\n# -------------------------------\n# 4. Model clàssic (Random Forest)\n# -------------------------------\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train_feats, y_train)\n\ny_pred = rf.predict(X_test_feats)\ny_proba = rf.predict_proba(X_test_feats)[:, 1]\n\nacc = accuracy_score(y_test, y_pred)\nroc = roc_auc_score(y_test, y_proba)\ncm = confusion_matrix(y_test, y_pred)\n\nprint(f\"Accuracy: {acc:.4f}\")\nprint(f\"ROC AUC:  {roc:.4f}\")\nprint(\"Confusion matrix:\")\nprint(cm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:30:14.675530Z","iopub.execute_input":"2025-05-30T18:30:14.675904Z","iopub.status.idle":"2025-05-30T18:30:36.586767Z","shell.execute_reply.started":"2025-05-30T18:30:14.675877Z","shell.execute_reply":"2025-05-30T18:30:36.585590Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.4937 - loss: 0.6983 - val_accuracy: 0.4572 - val_loss: 0.6960\nEpoch 2/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5377 - loss: 0.6910 - val_accuracy: 0.4704 - val_loss: 0.6941\nEpoch 3/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4924 - loss: 0.6938 - val_accuracy: 0.4507 - val_loss: 0.6959\nEpoch 4/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5337 - loss: 0.6918 - val_accuracy: 0.4474 - val_loss: 0.6982\nEpoch 5/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5214 - loss: 0.6928 - val_accuracy: 0.4474 - val_loss: 0.6994\nEpoch 6/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5186 - loss: 0.6912 - val_accuracy: 0.4474 - val_loss: 0.6970\nEpoch 7/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5290 - loss: 0.6909 - val_accuracy: 0.4474 - val_loss: 0.6967\nEpoch 8/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5036 - loss: 0.6950 - val_accuracy: 0.4474 - val_loss: 0.6963\nEpoch 9/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5339 - loss: 0.6914 - val_accuracy: 0.4474 - val_loss: 0.6994\nEpoch 10/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5210 - loss: 0.6932 - val_accuracy: 0.4572 - val_loss: 0.6948\nEpoch 11/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5316 - loss: 0.6924 - val_accuracy: 0.4474 - val_loss: 0.6978\nEpoch 12/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5325 - loss: 0.6912 - val_accuracy: 0.4375 - val_loss: 0.6963\nEpoch 13/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5017 - loss: 0.6934 - val_accuracy: 0.4474 - val_loss: 0.6968\nEpoch 14/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5352 - loss: 0.6912 - val_accuracy: 0.4737 - val_loss: 0.6938\nEpoch 15/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5086 - loss: 0.6919 - val_accuracy: 0.4507 - val_loss: 0.6987\nEpoch 16/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5284 - loss: 0.6915 - val_accuracy: 0.4539 - val_loss: 0.6981\nEpoch 17/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5031 - loss: 0.6942 - val_accuracy: 0.4474 - val_loss: 0.7003\nEpoch 18/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5146 - loss: 0.6931 - val_accuracy: 0.4474 - val_loss: 0.7016\nEpoch 19/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5381 - loss: 0.6905 - val_accuracy: 0.5461 - val_loss: 0.6916\nEpoch 20/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5019 - loss: 0.6932 - val_accuracy: 0.4539 - val_loss: 0.6987\nEpoch 21/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5069 - loss: 0.6925 - val_accuracy: 0.4474 - val_loss: 0.7015\nEpoch 22/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5308 - loss: 0.6901 - val_accuracy: 0.4605 - val_loss: 0.6955\nEpoch 23/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5183 - loss: 0.6932 - val_accuracy: 0.4671 - val_loss: 0.6949\nEpoch 24/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5213 - loss: 0.6913 - val_accuracy: 0.4704 - val_loss: 0.6961\nEpoch 25/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5278 - loss: 0.6909 - val_accuracy: 0.4671 - val_loss: 0.7021\nEpoch 26/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5369 - loss: 0.6916 - val_accuracy: 0.4671 - val_loss: 0.7080\nEpoch 27/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5155 - loss: 0.6955 - val_accuracy: 0.4934 - val_loss: 0.6978\nEpoch 28/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5377 - loss: 0.6895 - val_accuracy: 0.4539 - val_loss: 0.7052\nEpoch 29/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5231 - loss: 0.6901 - val_accuracy: 0.4704 - val_loss: 0.7052\nEpoch 30/30\n\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5446 - loss: 0.6885 - val_accuracy: 0.4737 - val_loss: 0.6985\n\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\nAccuracy: 0.5026\nROC AUC:  0.5599\nConfusion matrix:\n[[ 79 131]\n [ 58 112]]\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"## Añadimos información externa\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"external_features = [\n    '^IBEX_return', '^IBEX_lag1', '^IBEX_ma5',\n    '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5',\n    '^IXIC_return', '^IXIC_lag1',\n    '^VIX_return', '^VIX_lag1',\n    'CL=F_return', 'CL=F_lag1',\n    'US10Y_return'\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:38:33.094907Z","iopub.execute_input":"2025-05-30T18:38:33.095278Z","iopub.status.idle":"2025-05-30T18:38:33.100600Z","shell.execute_reply.started":"2025-05-30T18:38:33.095249Z","shell.execute_reply":"2025-05-30T18:38:33.099158Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Variables externes de context de mercat\nexternal_features = [\n    '^IBEX_return', '^IBEX_lag1', '^IBEX_ma5',\n    '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5',\n    '^IXIC_return', '^IXIC_lag1',\n    '^VIX_return', '^VIX_lag1',\n    'CL=F_return', 'CL=F_lag1',\n    'US10Y_return'\n]\n\ndf_clean_dict = {}\nassets_valids = []\n\nfor asset in assets:\n    # Variables internes (del propi actiu)\n    asset_cols = [\n        f'{asset}_return', f'{asset}_target',\n        f'{asset}_lag1', f'{asset}_lag2',\n        f'{asset}_ma5', f'{asset}_std5',\n        f'{asset}_volume_z'\n    ]\n    \n    # Combinem internes + externes\n    relevant_cols = asset_cols + external_features\n\n    # Verifiquem que totes les columnes existeixen al df\n    if all(col in df_features.columns for col in relevant_cols):\n        # Eliminem files amb NA\n        df_asset = df_features[relevant_cols].dropna()\n        num_files_valides = len(df_asset)\n\n        if num_files_valides >= 1900:\n            df_clean_dict[asset] = df_asset\n            assets_valids.append(asset)\n            print(f\"{asset}: {num_files_valides} files vàlides (✔)\")\n        else:\n            print(f\"{asset}: {num_files_valides} files vàlides (✘)\")\n    else:\n        missing = [col for col in relevant_cols if col not in df_features.columns]\n        print(f\"{asset}: Falten columnes {missing} (✘)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T18:39:50.008077Z","iopub.execute_input":"2025-05-30T18:39:50.008475Z","iopub.status.idle":"2025-05-30T18:39:50.023807Z","shell.execute_reply.started":"2025-05-30T18:39:50.008445Z","shell.execute_reply":"2025-05-30T18:39:50.021463Z"}},"outputs":[{"name":"stdout","text":"AAPL: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nAMS: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nAMZN: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nBBVA: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nCABK: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nCLNX: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nFER: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nGOOGL: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nGSPC: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nIBE: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nIBEX: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nITX: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nIXIC: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nJPM: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nLLY: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nMETA: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nMSFT: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nNVDA: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nSAN: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nTEF: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\nTSLA: Falten columnes ['^IBEX_return', '^IBEX_lag1', '^IBEX_ma5', '^GSPC_return', '^GSPC_lag1', '^GSPC_ma5', '^IXIC_return', '^IXIC_lag1', '^VIX_return', '^VIX_lag1', 'CL=F_return', 'CL=F_lag1', 'US10Y_return'] (✘)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}